0. Math For ML https://static.us.edusercontent.com/files/fp5iS7gSfEKiqEz5OchGseaY
1. pdf to cdf practice example: https://blogs.ubc.ca/math105/continuous-random-variables/example/ <br>
2. inner products and norms: https://www.princeton.edu/~aaa/Public/Teaching/ORF523/S17/ORF523_S17_Lec2_gh.pdf <br> 
3. gradient vector: https://acritch.com/media/math53/Critch_Math53_09Su_-_Nabla_Notation.pdf <br> https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/the-gradient<br>
4. Sigmoid derivative via chain rule: https://hausetutorials.netlify.app/posts/2019-12-01-neural-networks-deriving-the-sigmoid-derivative/#:~:text=The%20derivative%20of%20the%20sigmoid%20function%20%CF%83(x)%20is%20the,1%E2%88%92%CF%83(x). <br>
5. Derivative min? https://math.stackexchange.com/questions/150960/derivative-of-the-fx-y-minx-y <br>
6. Theory of convex functions: https://www.princeton.edu/~aaa/Public/Teaching/ORF523/S16/ORF523_S16_Lec7_gh.pdf  and https://see.stanford.edu/materials/lsocoee364a/03convexfunctions.pdf and mentioned in Theory of convex functions but more math  https://math.stackexchange.com/questions/2280341/why-is-every-p-norm-convex<br>
7. Convex Optimization Lecture Notes https://people.eecs.berkeley.edu/~elghaoui/Teaching/EE227BT/LectureNotes_EE227BT.pdf
8. Great content connecting KL Divergence and cross entropy loss https://www.youtube.com/watch?v=SxGYPqCgJWM and https://www.youtube.com/watch?v=Pwgpl9mKars
9. one page List of Derivative Rules https://www.math.ucdavis.edu/~kouba/Math17BHWDIRECTORY/Derivatives.pdf
